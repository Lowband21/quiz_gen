{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fAQKStuINe3G"
      },
      "outputs": [],
      "source": [
        "# @title üå¥ Change the values in this section\n",
        "\n",
        "# @markdown Select the source of the audio/video file to be transcribed\n",
        "input_format = \"gdrive\" #@param [\"gdrive\"]\n",
        "\n",
        "# @markdown Enter the URL of the YouTube video or the path of the audio file to be transcribed\n",
        "# file = \"/content/drive/MyDrive/WhisperVideo/audio1217199309.m4a\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as text file\n",
        "plain = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as an SRT file\n",
        "srt = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a VTT file\n",
        "vtt = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a TSV file\n",
        "tsv = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to download the transcribed file(s) locally\n",
        "download = False #@param {type:\"boolean\"}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LLoNmM0sKyIf"
      },
      "source": [
        "# üõ† Set Up\n",
        "\n",
        "The blocks below install all of the necessary Python libraries (including Whisper), configures Whisper, and contains code for various helper functions.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hfnRc8yPM79j"
      },
      "source": [
        "## ü§ù Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bF1enPzG-qKE",
        "outputId": "20ae874a-c3ed-479b-ad36-e578fba56ea4"
      },
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "\n",
        "#!pip install -q pytube\n",
        "#!pip install -q git+https://github.com/openai/whisper.git \n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import get_writer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E4eLQzNOo5_r"
      },
      "source": [
        "## üëã Whisper configuration\n",
        "\n",
        "This Colab use `medium.en`, [the medium-sized, English-only](https://github.com/openai/whisper#available-models-and-languages) Whisper model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCNc3EfV4EIt",
        "outputId": "bda88d69-c421-4704-ae91-243466801a28"
      },
      "outputs": [],
      "source": [
        "# Use CUDA, if available\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the desired model\n",
        "model = whisper.load_model(\"medium.en\").to(DEVICE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IvN1wRXbo-7C"
      },
      "source": [
        "## üí™ YouTube helper functions\n",
        "\n",
        "Code for helper functions when running Whisper on a YouTube video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLmwvJ3tM-CD"
      },
      "outputs": [],
      "source": [
        "def to_snake_case(name):\n",
        "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
        "\n",
        "# def download_youtube_audio(url,  file_name = None, out_dir = \".\"):\n",
        "#     \"Download the audio from a YouTube video\"\n",
        "#     yt = YouTube(url)\n",
        "#     if file_name is None:\n",
        "#         file_name = Path(out_dir, to_snake_case(yt.title)).with_suffix(\".mp4\")\n",
        "#     yt = (yt.streams\n",
        "#             .filter(only_audio = True, file_extension = \"mp4\")\n",
        "#             .order_by(\"abr\")\n",
        "#             .desc())\n",
        "#     return yt.first().download(filename = file_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ech5wPCwtO_P"
      },
      "source": [
        "# ‚úç Transcribing with Whisper\n",
        "\n",
        "Ultimately, calling Whisper is as easy as one line!\n",
        "* `result = model.transcribe(file)`\n",
        "\n",
        "The majority of this new `transcribe_file` function is actually just for exporting the results of the transcription as a text, VTT, or SRT file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22CwQZnOtGO1"
      },
      "outputs": [],
      "source": [
        "def transcribe_file(model, file, plain, srt, vtt, tsv, download):\n",
        "    \"\"\"\n",
        "    Runs Whisper on an audio file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: Whisper\n",
        "        The Whisper model instance.\n",
        "    \n",
        "    file: str\n",
        "        The file path of the file to be transcribed.\n",
        "\n",
        "    plain: bool\n",
        "        Whether to save the transcription as a text file or not.\n",
        "    \n",
        "    srt: bool\n",
        "        Whether to save the transcription as an SRT file or not.\n",
        "    \n",
        "    vtt: bool\n",
        "        Whether to save the transcription as a VTT file or not.\n",
        "    \n",
        "    tsv: bool\n",
        "        Whether to save the transcription as a TSV file or not.\n",
        "\n",
        "    download: bool\n",
        "        Whether to download the transcribed file(s) or not.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and\n",
        "    the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n",
        "    \"\"\"\n",
        "    file_path = dir + file\n",
        "    print(f\"Transcribing file: {file_path}\\n\")\n",
        "\n",
        "    output_directory = file_path\n",
        "\n",
        "    # Run Whisper\n",
        "    result = model.transcribe(file_path, verbose = False, language = \"en\")\n",
        "\n",
        "    if plain:\n",
        "        # txt_path = file_path.with_suffix(\".txt\")\n",
        "        \n",
        "        audio_path = dir + \"Audios/\" + file\n",
        "        text_path =  dir + \"Transcriptions/\" + file[:-4] + \".txt\" # Replace the  extension with .txt\n",
        "\n",
        "        print(f\"\\nCreating text file\")\n",
        "        \n",
        "        with open(text_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "\n",
        "        os.rename(file_path, audio_path)\n",
        "        \n",
        "    if srt:\n",
        "        print(f\"\\nCreating SRT file\")\n",
        "        srt_writer = get_writer(\"srt\", output_directory)\n",
        "        srt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if vtt:\n",
        "        print(f\"\\nCreating VTT file\")\n",
        "        vtt_writer = get_writer(\"vtt\", output_directory)\n",
        "        vtt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if tsv:\n",
        "        print(f\"\\nCreating TSV file\")\n",
        "\n",
        "        tsv_writer = get_writer(\"tsv\", output_directory)\n",
        "        tsv_writer(result, str(file_path.stem))\n",
        "\n",
        "    if download:\n",
        "        from google.colab import files\n",
        "        \n",
        "        colab_files = Path(\"/content\")\n",
        "        stem = file_path.stem\n",
        "\n",
        "        for colab_file in colab_files.glob(f\"{stem}*\"):\n",
        "            if colab_file.suffix in [\".txt\", \".srt\", \".vtt\", \".tsv\"]:\n",
        "                print(f\"Downloading {colab_file}\")\n",
        "                files.download(str(colab_file))\n",
        "      \n",
        "    return result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CLC_tpz6tgq6"
      },
      "source": [
        "# üí¨ Whisper it!\n",
        "\n",
        "This block actually calls `transcribe_file` üòâ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDTvtp86st15",
        "outputId": "1a03f169-a55e-42c3-fb6d-3d6d1dca419d"
      },
      "outputs": [],
      "source": [
        "dir = \"/home/lowband/dev/quiz_gen/Whisper/input/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngTGllHutSfo",
        "outputId": "921515b1-8e51-4024-897d-a716206d92bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1351Strings2.mp4\n",
            "Transcribing file: /home/lowband/dev/quiz_gen/Whisper/input/1351Strings2.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40505/40505 [00:14<00:00, 2733.42frames/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(audio_file)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Extract the audio from the video file using librosa\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# file = dir + audio_file\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Skip the file if it is not a video format\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[39m# Run Whisper on the specified file\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m result \u001b[39m=\u001b[39m transcribe_file(model, audio_file, plain, srt, vtt, tsv, download)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mResult: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m result)\n",
            "Cell \u001b[0;32mIn[5], line 71\u001b[0m, in \u001b[0;36mtranscribe_file\u001b[0;34m(model, file, plain, srt, vtt, tsv, download)\u001b[0m\n\u001b[1;32m     68\u001b[0m     tsv_writer(result, \u001b[39mstr\u001b[39m(file_path\u001b[39m.\u001b[39mstem))\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[1;32m     73\u001b[0m     colab_files \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39m/content\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m     stem \u001b[39m=\u001b[39m file_path\u001b[39m.\u001b[39mstem\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "folder = os.listdir(dir)\n",
        "\n",
        "# Loop through the audio files and transcribe them\n",
        "# for folder in dir:\n",
        "for audio_file in folder:\n",
        "  print(audio_file)\n",
        "  # Extract the audio from the video file using librosa\n",
        "  # file = dir + audio_file\n",
        "  # Skip the file if it is not a video format\n",
        "  #if not audio_file.endswith((\".mp4\", \".3gp\")):\n",
        "  #  continue\n",
        "\n",
        "\n",
        "  # Run Whisper on the specified file\n",
        "  result = transcribe_file(model, audio_file, plain, srt, vtt, tsv, download)\n",
        "\n",
        "  print(\"Result: \" + result)\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
