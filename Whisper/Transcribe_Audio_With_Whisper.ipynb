{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAQKStuINe3G"
      },
      "outputs": [],
      "source": [
        "# @title 🌴 Change the values in this section\n",
        "\n",
        "# @markdown Select the source of the audio/video file to be transcribed\n",
        "input_format = \"gdrive\" #@param [\"gdrive\"]\n",
        "\n",
        "# @markdown Enter the URL of the YouTube video or the path of the audio file to be transcribed\n",
        "# file = \"/content/drive/MyDrive/WhisperVideo/audio1217199309.m4a\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as text file\n",
        "plain = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as an SRT file\n",
        "srt = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a VTT file\n",
        "vtt = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a TSV file\n",
        "tsv = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to download the transcribed file(s) locally\n",
        "download = False #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLoNmM0sKyIf"
      },
      "source": [
        "# 🛠 Set Up\n",
        "\n",
        "The blocks below install all of the necessary Python libraries (including Whisper), configures Whisper, and contains code for various helper functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfnRc8yPM79j"
      },
      "source": [
        "## 🤝 Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bF1enPzG-qKE",
        "outputId": "20ae874a-c3ed-479b-ad36-e578fba56ea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Dependencies\n",
        "\n",
        "#!pip install -q pytube\n",
        "#!pip install -q git+https://github.com/openai/whisper.git \n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import get_writer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4eLQzNOo5_r"
      },
      "source": [
        "## 👋 Whisper configuration\n",
        "\n",
        "This Colab use `medium.en`, [the medium-sized, English-only](https://github.com/openai/whisper#available-models-and-languages) Whisper model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCNc3EfV4EIt",
        "outputId": "bda88d69-c421-4704-ae91-243466801a28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:10<00:00, 142MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# Use CUDA, if available\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the desired model\n",
        "model = whisper.load_model(\"medium.en\").to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvN1wRXbo-7C"
      },
      "source": [
        "## 💪 YouTube helper functions\n",
        "\n",
        "Code for helper functions when running Whisper on a YouTube video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLmwvJ3tM-CD"
      },
      "outputs": [],
      "source": [
        "def to_snake_case(name):\n",
        "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
        "\n",
        "# def download_youtube_audio(url,  file_name = None, out_dir = \".\"):\n",
        "#     \"Download the audio from a YouTube video\"\n",
        "#     yt = YouTube(url)\n",
        "#     if file_name is None:\n",
        "#         file_name = Path(out_dir, to_snake_case(yt.title)).with_suffix(\".mp4\")\n",
        "#     yt = (yt.streams\n",
        "#             .filter(only_audio = True, file_extension = \"mp4\")\n",
        "#             .order_by(\"abr\")\n",
        "#             .desc())\n",
        "#     return yt.first().download(filename = file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ech5wPCwtO_P"
      },
      "source": [
        "# ✍ Transcribing with Whisper\n",
        "\n",
        "Ultimately, calling Whisper is as easy as one line!\n",
        "* `result = model.transcribe(file)`\n",
        "\n",
        "The majority of this new `transcribe_file` function is actually just for exporting the results of the transcription as a text, VTT, or SRT file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV6vulHEXYt6"
      },
      "outputs": [],
      "source": [
        "dir = \"/content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_27_19/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22CwQZnOtGO1"
      },
      "outputs": [],
      "source": [
        "def transcribe_file(model, file, plain, srt, vtt, tsv, download):\n",
        "    \"\"\"\n",
        "    Runs Whisper on an audio file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: Whisper\n",
        "        The Whisper model instance.\n",
        "    \n",
        "    file: str\n",
        "        The file path of the file to be transcribed.\n",
        "\n",
        "    plain: bool\n",
        "        Whether to save the transcription as a text file or not.\n",
        "    \n",
        "    srt: bool\n",
        "        Whether to save the transcription as an SRT file or not.\n",
        "    \n",
        "    vtt: bool\n",
        "        Whether to save the transcription as a VTT file or not.\n",
        "    \n",
        "    tsv: bool\n",
        "        Whether to save the transcription as a TSV file or not.\n",
        "\n",
        "    download: bool\n",
        "        Whether to download the transcribed file(s) or not.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and\n",
        "    the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n",
        "    \"\"\"\n",
        "    file_path = dir + file\n",
        "    print(f\"Transcribing file: {file_path}\\n\")\n",
        "\n",
        "    output_directory = file_path\n",
        "\n",
        "    # Run Whisper\n",
        "    result = model.transcribe(file_path, verbose = False, language = \"en\")\n",
        "\n",
        "    if plain:\n",
        "        # txt_path = file_path.with_suffix(\".txt\")\n",
        "        \n",
        "        audio_path = dir + \"Audios/\" + file\n",
        "        text_path =  dir + \"Transcriptions/\" + file[:-4] + \".txt\" # Replace the  extension with .txt\n",
        "\n",
        "        print(f\"\\nCreating text file\")\n",
        "        \n",
        "        with open(text_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "\n",
        "        os.rename(file_path, audio_path)\n",
        "        \n",
        "    if srt:\n",
        "        print(f\"\\nCreating SRT file\")\n",
        "        srt_writer = get_writer(\"srt\", output_directory)\n",
        "        srt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if vtt:\n",
        "        print(f\"\\nCreating VTT file\")\n",
        "        vtt_writer = get_writer(\"vtt\", output_directory)\n",
        "        vtt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if tsv:\n",
        "        print(f\"\\nCreating TSV file\")\n",
        "\n",
        "        tsv_writer = get_writer(\"tsv\", output_directory)\n",
        "        tsv_writer(result, str(file_path.stem))\n",
        "\n",
        "    if download:\n",
        "        from google.colab import files\n",
        "        \n",
        "        colab_files = Path(\"/content\")\n",
        "        stem = file_path.stem\n",
        "\n",
        "        for colab_file in colab_files.glob(f\"{stem}*\"):\n",
        "            if colab_file.suffix in [\".txt\", \".srt\", \".vtt\", \".tsv\"]:\n",
        "                print(f\"Downloading {colab_file}\")\n",
        "                files.download(str(colab_file))\n",
        "      \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLC_tpz6tgq6"
      },
      "source": [
        "# 💬 Whisper it!\n",
        "\n",
        "This block actually calls `transcribe_file` 😉\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDTvtp86st15",
        "outputId": "1a03f169-a55e-42c3-fb6d-3d6d1dca419d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "dir = \"/home/lowband/dev/quiz_gen\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngTGllHutSfo",
        "outputId": "921515b1-8e51-4024-897d-a716206d92bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribing file: /content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_28_19/Jaclyn-S5982297334085560336717-2019.02.28.11.32.28.9-2019.02.28.11.33.03.0-audio-index_3-obs_5.3gp\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 55848/55848 [01:32<00:00, 601.74frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n",
            "Transcribing file: /content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_28_19/Jaclyn-S9732230502477918641758-2019.02.28.08.34.21.3-2019.02.28.08.35.24.1-audio-index_2-obs_4.3gp\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39684/39684 [01:02<00:00, 631.40frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n",
            "Transcribing file: /content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_28_19/Jaclyn-S9732230502477918641758-2019.02.28.08.42.23.3-2019.02.28.08.43.10.6-audio-index_3-obs_5.3gp\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32300/32300 [00:45<00:00, 702.69frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n",
            "Transcribing file: /content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_28_19/Jaclyn-S9732230502477918641758-2019.02.28.08.58.39.1-2019.02.28.08.59.09.6-audio-index_6-obs_8.3gp\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13072/13072 [00:27<00:00, 479.07frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n",
            "Transcribing file: /content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_28_19/Jaclyn-S9732230502477918641758-2019.02.28.08.48.40.2-2019.02.28.08.49.12.0-audio-index_4-obs_6.3gp\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31014/31014 [01:07<00:00, 459.41frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n",
            "Transcribing file: /content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_28_19/Jaclyn-S9732230502477918641758-2019.02.28.08.54.25.2-2019.02.28.08.55.08.3-audio-index_5-obs_7.3gp\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20620/20620 [00:35<00:00, 579.24frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n",
            "Transcribing file: /content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_28_19/Jaclyn-S9732230502477918641758-2019.02.28.09.01.29.1-2019.02.28.09.01.45.7-audio-index_7-obs_9.3gp\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 34590/34590 [00:57<00:00, 598.65frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n",
            "Transcribing file: /content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_28_19/Jaclyn-S9732230502477918641758-2019.02.28.09.07.49.1-2019.02.28.09.08.08.3-audio-index_8-obs_10.3gp\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9906/9906 [00:14<00:00, 701.04frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n",
            "Transcribing file: /content/drive/MyDrive/Meigs_Feb_2019/Jaclyn_02_28_19/Jaclyn-S9732230502477918641758-2019.02.28.09.10.07.6-2019.02.28.09.10.48.2-audio-index_9-obs_11.3gp\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15514/15514 [00:22<00:00, 694.88frames/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating text file\n",
            "All Done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "folder = os.listdir(dir)\n",
        "\n",
        "# Loop through the audio files and transcribe them\n",
        "# for folder in dir:\n",
        "for audio_file in folder:\n",
        "  # Extract the audio from the video file using librosa\n",
        "  # file = dir + audio_file\n",
        "  # Skip the file if it is not a video format\n",
        "  if not audio_file.endswith((\".mp3\", \".3gp\")):\n",
        "    continue\n",
        "\n",
        "  # Run Whisper on the specified file\n",
        "  result = transcribe_file(model, audio_file, plain, srt, vtt, tsv, download)\n",
        "\n",
        "print(\"All Done!\")\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
